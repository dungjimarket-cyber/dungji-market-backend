"""
OpenAIë¥¼ í™œìš©í•œ ìƒë‹´ í”Œë¡œìš° ìë™ ìƒì„±
"""
import json
import logging
from django.conf import settings

logger = logging.getLogger(__name__)


def generate_consultation_flow(category_name: str, additional_prompt: str = '') -> dict:
    """
    OpenAIë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒë‹´ í”Œë¡œìš° ìƒì„±

    Args:
        category_name: ì—…ì¢… ì´ë¦„ (ì˜ˆ: "ì„¸ë¬´ì‚¬", "ë³€í˜¸ì‚¬")
        additional_prompt: ì¶”ê°€ ì§€ì‹œì‚¬í•­

    Returns:
        {
            'success': bool,
            'flows': list,  # ìƒì„±ëœ í”Œë¡œìš° ë°ì´í„°
            'error': str,   # ì—ëŸ¬ ë©”ì‹œì§€ (ì‹¤íŒ¨ ì‹œ)
        }
    """
    try:
        import openai

        api_key = getattr(settings, 'OPENAI_API_KEY', None)
        if not api_key:
            return {'success': False, 'error': 'OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'}

        client = openai.OpenAI(api_key=api_key)

        system_prompt = """ë‹¹ì‹ ì€ ìƒë‹´ í”Œë¡œìš° ì„¤ê³„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì‚¬ìš©ìê°€ ì§€ì •í•œ ì—…ì¢…ì— ë§ëŠ” ìƒë‹´ ì§ˆë¬¸ í”Œë¡œìš°ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ìƒì„±í•´ì£¼ì„¸ìš”.

ê·œì¹™:
1. ëª©ì  ì¤‘ì‹¬ ì„¤ê³„: ì²« ì§ˆë¬¸ì€ "ì–´ë–¤ ë„ì›€ì´ í•„ìš”í•˜ì„¸ìš”?" í˜•íƒœë¡œ ê³ ê°ì˜ ë‹ˆì¦ˆë¥¼ íŒŒì•…
2. ì¡°ê±´ë¶€ ì§ˆë¬¸: ì´ì „ ì„ íƒì— ë”°ë¼ ë‹¤ë¥¸ ì§ˆë¬¸ì„ í‘œì‹œ (depends_on_step, depends_on_options ì‚¬ìš©)
3. 3-5ë‹¨ê³„ ì •ë„ì˜ ì§ˆë¬¸ìœ¼ë¡œ êµ¬ì„±
4. ë§ˆì§€ë§‰ì— ì§ì ‘ ì…ë ¥ ì˜µì…˜ ì œê³µ (is_custom_input: true)
5. ì ì ˆí•œ ì´ëª¨ì§€ ì•„ì´ì½˜ ì‚¬ìš©

ì¶œë ¥ í˜•ì‹ (JSON):
{
  "flows": [
    {
      "step_number": 1,
      "question": "ì–´ë–¤ ë„ì›€ì´ í•„ìš”í•˜ì„¸ìš”?",
      "is_required": true,
      "depends_on_step": null,
      "depends_on_options": [],
      "options": [
        {"key": "option_key", "label": "ì„ íƒì§€ ë¼ë²¨", "icon": "ğŸ“‹", "description": "ì„¤ëª… (ì„ íƒ)"},
        {"key": "custom", "label": "ì§ì ‘ ì…ë ¥", "icon": "ğŸ“", "is_custom_input": true}
      ]
    },
    {
      "step_number": 2,
      "question": "êµ¬ì²´ì ì¸ ìƒí™©ì€?",
      "is_required": true,
      "depends_on_step": 1,
      "depends_on_options": ["option_key"],
      "options": [...]
    }
  ]
}

ì‹¤ì œ í”Œë«í¼(ì„¸ë¬´í†µ, ë¡œí†¡, ì§ì‹¸, ì§‘ë‹¥ ë“±)ì˜ ìƒë‹´ ì§ˆë¬¸ íŒ¨í„´ì„ ì°¸ê³ í•˜ì„¸ìš”."""

        user_prompt = f"""ì—…ì¢…: {category_name}

ì´ ì—…ì¢…ì— ë§ëŠ” ìƒë‹´ ì§ˆë¬¸ í”Œë¡œìš°ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.
ê³ ê°ì´ ë¬´ì—‡ì„ ì›í•˜ëŠ”ì§€ íŒŒì•…í•˜ê³ , ì ì ˆí•œ ì„¸ë¶€ ì§ˆë¬¸ìœ¼ë¡œ ì´ì–´ì§€ë„ë¡ ì„¤ê³„í•´ì£¼ì„¸ìš”.

{additional_prompt if additional_prompt else ''}

JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”."""

        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.7,
            max_tokens=4000,
            response_format={"type": "json_object"}
        )

        content = response.choices[0].message.content
        result = json.loads(content)

        flows = result.get('flows', [])

        if not flows:
            return {'success': False, 'error': 'AIê°€ í”Œë¡œìš°ë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.'}

        return {
            'success': True,
            'flows': flows,
        }

    except ImportError:
        return {'success': False, 'error': 'openai íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'}
    except json.JSONDecodeError as e:
        logger.error(f"JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
        return {'success': False, 'error': 'AI ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨'}
    except Exception as e:
        logger.exception("AI í”Œë¡œìš° ìƒì„± ì˜¤ë¥˜")
        return {'success': False, 'error': str(e)}


def improve_consultation_flow(category_name: str, current_flows: list, improvement_prompt: str) -> dict:
    """
    ê¸°ì¡´ í”Œë¡œìš°ë¥¼ ê°œì„ 

    Args:
        category_name: ì—…ì¢… ì´ë¦„
        current_flows: í˜„ì¬ í”Œë¡œìš° ë°ì´í„°
        improvement_prompt: ê°œì„  ì§€ì‹œì‚¬í•­

    Returns:
        {
            'success': bool,
            'flows': list,
            'error': str,
        }
    """
    try:
        import openai

        api_key = getattr(settings, 'OPENAI_API_KEY', None)
        if not api_key:
            return {'success': False, 'error': 'OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'}

        client = openai.OpenAI(api_key=api_key)

        system_prompt = """ë‹¹ì‹ ì€ ìƒë‹´ í”Œë¡œìš° ê°œì„  ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ê¸°ì¡´ ìƒë‹´ í”Œë¡œìš°ë¥¼ ë¶„ì„í•˜ê³  ì‚¬ìš©ìì˜ ì§€ì‹œì— ë”°ë¼ ê°œì„ í•´ì£¼ì„¸ìš”.

ì¶œë ¥ì€ ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œ í•´ì£¼ì„¸ìš”:
{
  "flows": [...]
}"""

        user_prompt = f"""ì—…ì¢…: {category_name}

í˜„ì¬ í”Œë¡œìš°:
{json.dumps(current_flows, ensure_ascii=False, indent=2)}

ê°œì„  ìš”ì²­: {improvement_prompt}

ê°œì„ ëœ í”Œë¡œìš°ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”."""

        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.7,
            max_tokens=4000,
            response_format={"type": "json_object"}
        )

        content = response.choices[0].message.content
        result = json.loads(content)

        flows = result.get('flows', [])

        return {
            'success': True,
            'flows': flows,
        }

    except Exception as e:
        logger.exception("AI í”Œë¡œìš° ê°œì„  ì˜¤ë¥˜")
        return {'success': False, 'error': str(e)}
