"""
ì§€ì—­ ì—…ì²´ ì •ë³´ ViewSet
"""
from rest_framework import viewsets, filters, status
from rest_framework.decorators import action, api_view, permission_classes as perm_decorator
from rest_framework.response import Response
from rest_framework.permissions import AllowAny
from django_filters.rest_framework import DjangoFilterBackend
from django.db.models import F
from django.utils import timezone
from django.http import HttpResponse
from django.views.decorators.csrf import csrf_exempt
import requests
import logging

logger = logging.getLogger(__name__)

from api.models_local_business import (
    LocalBusinessCategory,
    LocalBusiness,
    LocalBusinessView
)
from api.serializers_local_business import (
    LocalBusinessCategorySerializer,
    LocalBusinessListSerializer,
    LocalBusinessDetailSerializer
)


class LocalBusinessCategoryViewSet(viewsets.ReadOnlyModelViewSet):
    """ì—…ì¢… ì¹´í…Œê³ ë¦¬ ViewSet (ì½ê¸° ì „ìš©)"""

    queryset = LocalBusinessCategory.objects.filter(is_active=True)
    serializer_class = LocalBusinessCategorySerializer
    permission_classes = [AllowAny]

    def get_queryset(self):
        """í™œì„±í™”ëœ ì¹´í…Œê³ ë¦¬ë§Œ ì •ë ¬ìˆœìœ¼ë¡œ"""
        return self.queryset.order_by('order_index', 'name')

    def list(self, request, *args, **kwargs):
        """ì¹´í…Œê³ ë¦¬ ëª©ë¡ ì¡°íšŒ - ì„¸ë¬´ì‚¬+íšŒê³„ì‚¬, ë²•ë¬´ì‚¬+ë³€í˜¸ì‚¬ í†µí•©

        ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°:
        - raw=true: í†µí•© ì—†ì´ ì›ë³¸ ì¹´í…Œê³ ë¦¬ 10ê°œ ë°˜í™˜ (ì „ë¬¸ê°€ íšŒì›ê°€ì…ìš©)
        """
        from django.db.models import Q

        queryset = self.get_queryset()
        serializer = self.get_serializer(queryset, many=True)

        # raw=trueì¸ ê²½ìš° ì›ë³¸ ì¹´í…Œê³ ë¦¬ ê·¸ëŒ€ë¡œ ë°˜í™˜ (ì „ë¬¸ê°€ íšŒì›ê°€ì…ìš©)
        raw_mode = request.query_params.get('raw', '').lower() == 'true'
        if raw_mode:
            return Response(serializer.data)

        # í†µí•©í•  ì¹´í…Œê³ ë¦¬ ì²˜ë¦¬
        # ì„¸ë¬´ì‚¬+íšŒê³„ì‚¬ â†’ ì„¸ë¬´Â·íšŒê³„, ë²•ë¬´ì‚¬+ë³€í˜¸ì‚¬ â†’ ë²•ë¥  ì„œë¹„ìŠ¤, ì²­ì†Œ+ì´ì‚¬ â†’ ì²­ì†ŒÂ·ì´ì‚¬
        categories = []
        tax_accounting_added = False
        legal_service_added = False
        cleaning_moving_added = False
        skip_categories = []

        for cat_data in serializer.data:
            category_name = cat_data['name']

            # ì„¸ë¬´ì‚¬+íšŒê³„ì‚¬ í†µí•©
            if category_name in ['ì„¸ë¬´ì‚¬', 'íšŒê³„ì‚¬']:
                skip_categories.append(category_name)
                if not tax_accounting_added:
                    tax_accounting_count = LocalBusiness.objects.filter(
                        Q(category__name='ì„¸ë¬´ì‚¬') | Q(category__name='íšŒê³„ì‚¬')
                    ).count()
                    categories.append({
                        'id': 'tax_accounting',
                        'name': 'ì„¸ë¬´Â·íšŒê³„',
                        'name_en': 'tax & accounting',
                        'icon': 'ğŸ’¼',
                        'google_place_type': 'accounting',
                        'description': 'ì„¸ë¬´ì‚¬, íšŒê³„ì‚¬ ë“± ì„¸ë¬´Â·íšŒê³„ ì „ë¬¸ ì„œë¹„ìŠ¤',
                        'order_index': 1,
                        'is_active': True,
                        'business_count': tax_accounting_count,
                        'merged_categories': ['ì„¸ë¬´ì‚¬', 'íšŒê³„ì‚¬']
                    })
                    tax_accounting_added = True

            # ë²•ë¬´ì‚¬+ë³€í˜¸ì‚¬ í†µí•©
            elif category_name in ['ë²•ë¬´ì‚¬', 'ë³€í˜¸ì‚¬']:
                skip_categories.append(category_name)
                if not legal_service_added:
                    legal_service_count = LocalBusiness.objects.filter(
                        Q(category__name='ë²•ë¬´ì‚¬') | Q(category__name='ë³€í˜¸ì‚¬')
                    ).count()
                    categories.append({
                        'id': 'legal_service',
                        'name': 'ë²•ë¥  ì„œë¹„ìŠ¤',
                        'name_en': 'legal service',
                        'icon': 'âš–ï¸',
                        'google_place_type': 'legal',
                        'description': 'ë³€í˜¸ì‚¬, ë²•ë¬´ì‚¬ ë“± ë²•ë¥  ì „ë¬¸ ì„œë¹„ìŠ¤',
                        'order_index': 2,
                        'is_active': True,
                        'business_count': legal_service_count,
                        'merged_categories': ['ë³€í˜¸ì‚¬', 'ë²•ë¬´ì‚¬']
                    })
                    legal_service_added = True

            # ì²­ì†Œ+ì´ì‚¬ í†µí•©
            elif category_name in ['ì²­ì†Œ ì „ë¬¸', 'ì´ì‚¬ ì „ë¬¸']:
                skip_categories.append(category_name)
                if not cleaning_moving_added:
                    cleaning_moving_count = LocalBusiness.objects.filter(
                        Q(category__name='ì²­ì†Œ ì „ë¬¸') | Q(category__name='ì´ì‚¬ ì „ë¬¸')
                    ).count()
                    categories.append({
                        'id': 'cleaning_moving',
                        'name': 'ì²­ì†ŒÂ·ì´ì‚¬',
                        'name_en': 'cleaning & moving',
                        'icon': 'ğŸ§¹',
                        'google_place_type': 'service',
                        'description': 'ì²­ì†Œ, ì´ì‚¬ ì „ë¬¸ ì„œë¹„ìŠ¤',
                        'order_index': 9,
                        'is_active': True,
                        'business_count': cleaning_moving_count,
                        'merged_categories': ['ì²­ì†Œ ì „ë¬¸', 'ì´ì‚¬ ì „ë¬¸']
                    })
                    cleaning_moving_added = True

            # ë‚˜ë¨¸ì§€ ì¹´í…Œê³ ë¦¬ëŠ” ê·¸ëŒ€ë¡œ ì¶”ê°€
            else:
                business_count = LocalBusiness.objects.filter(category_id=cat_data['id']).count()
                cat_data['business_count'] = business_count
                categories.append(cat_data)

        return Response(categories)


class LocalBusinessViewSet(viewsets.ModelViewSet):
    """ì§€ì—­ ì—…ì²´ ViewSet"""

    queryset = LocalBusiness.objects.select_related(
        'category'
    ).prefetch_related('links')
    permission_classes = [AllowAny]
    http_method_names = ['get', 'post', 'put', 'patch', 'delete', 'head', 'options']  # ëª…ì‹œì ìœ¼ë¡œ POST í—ˆìš©
    filter_backends = [DjangoFilterBackend, filters.SearchFilter, filters.OrderingFilter]
    filterset_fields = ['is_verified']  # categoryëŠ” get_querysetì—ì„œ ì»¤ìŠ¤í…€ ì²˜ë¦¬
    search_fields = ['name', 'address']
    ordering_fields = ['popularity_score', 'rating', 'review_count', 'rank_in_region', 'created_at']
    ordering = ['-popularity_score']  # ê¸°ë³¸ ì •ë ¬: ì¸ê¸°ë„ìˆœ (ë†’ì€ìˆœ)

    # Version marker for deployment verification
    _deployment_version = "2025-01-23-v2"

    def get_queryset(self):
        """ì»¤ìŠ¤í…€ í•„í„°ë§"""
        from django.db.models import Q

        queryset = super().get_queryset()

        # region_name__icontains íŒŒë¼ë¯¸í„° ì²˜ë¦¬
        region_filter = self.request.query_params.get('region_name__icontains')
        if region_filter:
            queryset = queryset.filter(region_name__icontains=region_filter)

        # í†µí•© ì¹´í…Œê³ ë¦¬ í•„í„°ë§ ì²˜ë¦¬
        category_filter = self.request.query_params.get('category')
        if category_filter:
            if category_filter == 'tax_accounting':
                # ì„¸ë¬´Â·íšŒê³„: ì„¸ë¬´ì‚¬ + íšŒê³„ì‚¬
                queryset = queryset.filter(
                    Q(category__name='ì„¸ë¬´ì‚¬') | Q(category__name='íšŒê³„ì‚¬')
                )
            elif category_filter == 'legal_service':
                # ë²•ë¥  ì„œë¹„ìŠ¤: ë³€í˜¸ì‚¬ + ë²•ë¬´ì‚¬
                queryset = queryset.filter(
                    Q(category__name='ë³€í˜¸ì‚¬') | Q(category__name='ë²•ë¬´ì‚¬')
                )
            elif category_filter == 'cleaning_moving':
                # ì²­ì†ŒÂ·ì´ì‚¬: ì²­ì†Œ ì „ë¬¸ + ì´ì‚¬ ì „ë¬¸
                queryset = queryset.filter(
                    Q(category__name='ì²­ì†Œ ì „ë¬¸') | Q(category__name='ì´ì‚¬ ì „ë¬¸')
                )
            else:
                # ì¼ë°˜ ì¹´í…Œê³ ë¦¬ ID í•„í„°ë§
                queryset = queryset.filter(category_id=category_filter)

        return queryset

    def get_serializer_class(self):
        """ì•¡ì…˜ë³„ Serializer ì„ íƒ"""
        if self.action == 'retrieve':
            return LocalBusinessDetailSerializer
        return LocalBusinessListSerializer

    def retrieve(self, request, *args, **kwargs):
        """ìƒì„¸ ì¡°íšŒ ì‹œ ì¡°íšŒìˆ˜ ì¦ê°€"""
        instance = self.get_object()

        # ì¡°íšŒìˆ˜ ì¦ê°€
        LocalBusiness.objects.filter(pk=instance.pk).update(
            view_count=F('view_count') + 1
        )

        # ì¡°íšŒ ë¡œê·¸ ê¸°ë¡
        ip_address = self.get_client_ip(request)
        LocalBusinessView.objects.create(
            business=instance,
            user=request.user if request.user.is_authenticated else None,
            ip_address=ip_address
        )

        # ì¸ìŠ¤í„´ìŠ¤ ìƒˆë¡œê³ ì¹¨ (view_count ì—…ë°ì´íŠ¸ ë°˜ì˜)
        instance.refresh_from_db()

        serializer = self.get_serializer(instance)
        return Response(serializer.data)

    def get_client_ip(self, request):
        """í´ë¼ì´ì–¸íŠ¸ IP ì£¼ì†Œ ì¶”ì¶œ"""
        x_forwarded_for = request.META.get('HTTP_X_FORWARDED_FOR')
        if x_forwarded_for:
            ip = x_forwarded_for.split(',')[0]
        else:
            ip = request.META.get('REMOTE_ADDR')
        return ip

    @action(detail=False, methods=['get'])
    def by_region_category(self, request):
        """ì§€ì—­+ì—…ì¢…ë³„ ìƒìœ„ ì—…ì²´ ì¡°íšŒ

        Query Params:
            - region: ì§€ì—­ëª… (ì˜ˆ: ê°•ë‚¨êµ¬, ìˆ˜ì›ì‹œ)
            - category: ì¹´í…Œê³ ë¦¬ ID
            - limit: ì¡°íšŒ ê°œìˆ˜ (ê¸°ë³¸: 5)
        """
        region_name = request.query_params.get('region')
        category_id = request.query_params.get('category')
        limit = int(request.query_params.get('limit', 5))

        if not region_name or not category_id:
            return Response(
                {'error': 'regionê³¼ category íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤'},
                status=status.HTTP_400_BAD_REQUEST
            )

        businesses = self.queryset.filter(
            region_name=region_name,
            category_id=category_id
        ).order_by('rank_in_region')[:limit]

        serializer = self.get_serializer(businesses, many=True)
        return Response(serializer.data)

    @action(detail=False, methods=['get'])
    def popular(self, request):
        """ì¸ê¸° ì—…ì²´ ì¡°íšŒ (ì „ì²´)

        Query Params:
            - category: ì¹´í…Œê³ ë¦¬ ID (ì„ íƒ)
            - limit: ì¡°íšŒ ê°œìˆ˜ (ê¸°ë³¸: 10)
        """
        category_id = request.query_params.get('category')
        limit = int(request.query_params.get('limit', 10))

        businesses = self.queryset.order_by('-popularity_score')

        if category_id:
            businesses = businesses.filter(category_id=category_id)

        businesses = businesses[:limit]

        serializer = self.get_serializer(businesses, many=True)
        return Response(serializer.data)

    @action(detail=False, methods=['get'])
    def new(self, request):
        """ìµœê·¼ ë“±ë¡ ì—…ì²´ ì¡°íšŒ (30ì¼ ì´ë‚´)

        Query Params:
            - category: ì¹´í…Œê³ ë¦¬ ID (ì„ íƒ)
            - limit: ì¡°íšŒ ê°œìˆ˜ (ê¸°ë³¸: 10)
        """
        from datetime import timedelta

        category_id = request.query_params.get('category')
        limit = int(request.query_params.get('limit', 10))

        # 30ì¼ ì´ë‚´ ë“±ë¡ëœ ì—…ì²´
        thirty_days_ago = timezone.now() - timedelta(days=30)
        businesses = self.queryset.filter(
            created_at__gte=thirty_days_ago
        ).order_by('-created_at')

        if category_id:
            businesses = businesses.filter(category_id=category_id)

        businesses = businesses[:limit]

        serializer = self.get_serializer(businesses, many=True)
        return Response(serializer.data)

    @action(detail=False, methods=['post'])
    def generate_summary(self, request):
        """ë¦¬ë·°ë¥¼ ë°›ì•„ì„œ AI ìš”ì•½ ìƒì„±"""
        from api.utils_ai_summary import generate_business_summary

        business_name = request.data.get('business_name')
        reviews = request.data.get('reviews', [])

        if not business_name:
            return Response(
                {'error': 'business_nameì´ í•„ìš”í•©ë‹ˆë‹¤'},
                status=status.HTTP_400_BAD_REQUEST
            )

        if not reviews or len(reviews) == 0:
            return Response(
                {'summary': None, 'message': 'ë¦¬ë·°ê°€ ì—†ì–´ ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤'}
            )

        # AI ìš”ì•½ ìƒì„±
        try:
            summary, error_msg = generate_business_summary(reviews, business_name)

            if summary:
                return Response({
                    'success': True,
                    'summary': summary
                })
            else:
                # ë¦¬ë·° ì—†ìŒ/í…ìŠ¤íŠ¸ ì—†ìŒì€ ì •ìƒ ì‘ë‹µ (200 OK)
                if error_msg in ["ë¦¬ë·° ë°ì´í„° ì—†ìŒ", "í…ìŠ¤íŠ¸ ë¦¬ë·° ì—†ìŒ (í‰ì ë§Œ ì¡´ì¬)"]:
                    return Response({
                        'success': False,
                        'summary': None,
                        'reason': error_msg  # 500 ì•„ë‹Œ 200ìœ¼ë¡œ ë°˜í™˜
                    })
                # OpenAI API ì˜¤ë¥˜ë§Œ 500
                else:
                    return Response(
                        {'success': False, 'error': error_msg or 'AI ìš”ì•½ ìƒì„± ì‹¤íŒ¨', 'summary': None},
                        status=status.HTTP_500_INTERNAL_SERVER_ERROR
                    )
        except Exception as e:
            logger.error(f'AI ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}')
            return Response(
                {'success': False, 'error': f'AI ìš”ì•½ ìƒì„± ì˜¤ë¥˜: {str(e)}', 'summary': None},
                status=status.HTTP_500_INTERNAL_SERVER_ERROR
            )

    def download_and_save_photo(self, photo_url, business_name, google_place_id):
        """Google ì´ë¯¸ì§€ë¥¼ ë‹¤ìš´ë¡œë“œí•´ì„œ custom_photo í•„ë“œì— ì €ì¥ (ImageField ì‚¬ìš©)"""
        from django.core.files.base import ContentFile
        import uuid

        if not photo_url:
            return None

        try:
            # Google ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
            response = requests.get(photo_url, timeout=10)
            if response.status_code != 200:
                logger.error(f'Failed to download photo: {response.status_code}')
                return None

            # íŒŒì¼ëª… ìƒì„±
            file_extension = 'jpg'
            filename = f"{google_place_id}_{uuid.uuid4().hex[:8]}.{file_extension}"

            # ContentFile ê°ì²´ ìƒì„± (ImageField.save()ì— ì‚¬ìš©)
            return ContentFile(response.content), filename

        except Exception as e:
            logger.error(f'Error downloading photo for {business_name}: {str(e)}')
            return None

    @action(detail=False, methods=['post'])
    def bulk_create(self, request):
        """í”„ë¡ íŠ¸ì—ì„œ ìˆ˜ì§‘í•œ ì—…ì²´ ë°ì´í„° ì¼ê´„ ì €ì¥ (30ì¼ ìºì‹± ì •ì±… + S3 ì´ë¯¸ì§€ ì €ì¥)"""
        from django.db import transaction
        from decimal import Decimal
        from django.utils import timezone
        from datetime import timedelta

        businesses_data = request.data.get('businesses', [])

        if not businesses_data:
            return Response(
                {'error': 'businesses ë°°ì—´ì´ í•„ìš”í•©ë‹ˆë‹¤'},
                status=status.HTTP_400_BAD_REQUEST
            )

        created_count = 0
        updated_count = 0
        skipped_count = 0
        errors = []

        # 30ì¼ ê¸°ì¤€
        thirty_days_ago = timezone.now() - timedelta(days=30)

        for business_data in businesses_data:
            try:
                with transaction.atomic():
                    category_id = business_data.get('category_id')
                    if not category_id:
                        errors.append(f"{business_data.get('name')}: category_id í•„ìˆ˜")
                        continue

                    category = LocalBusinessCategory.objects.get(id=category_id)
                    google_place_id = business_data['google_place_id']

                    # ê¸°ì¡´ ì—…ì²´ í™•ì¸
                    try:
                        existing = LocalBusiness.objects.get(google_place_id=google_place_id)

                        # 30ì¼ ì´ë‚´ ì—…ë°ì´íŠ¸ëœ ì—…ì²´ëŠ” AI ìš”ì•½ë§Œ ì—…ë°ì´íŠ¸
                        if existing.last_synced_at and existing.last_synced_at > thirty_days_ago:
                            new_summary = business_data.get('editorial_summary')

                            # ê¸°ì¡´ ìš”ì•½ì´ ì—†ê³  ìƒˆ ìš”ì•½ì´ ìˆìœ¼ë©´ ì €ì¥
                            if not existing.editorial_summary and new_summary:
                                logger.info(f"[UPDATE] {business_data.get('name')}: ìƒˆ AI ìš”ì•½ ì¶”ê°€ - {new_summary}")
                                existing.editorial_summary = new_summary
                                existing.save(update_fields=['editorial_summary'])
                                updated_count += 1
                            # ê¸°ì¡´ ìš”ì•½ì´ ìˆê³  ìƒˆ ìš”ì•½ì´ ìˆìœ¼ë©´ ì—…ë°ì´íŠ¸
                            elif existing.editorial_summary and new_summary:
                                logger.info(f"[UPDATE] {business_data.get('name')}: AI ìš”ì•½ ê°±ì‹  - {new_summary}")
                                existing.editorial_summary = new_summary
                                existing.save(update_fields=['editorial_summary'])
                                updated_count += 1
                            # ë‘˜ ë‹¤ ì—†ìœ¼ë©´ skip
                            else:
                                skipped_count += 1
                            continue

                        # 30ì¼ ì§€ë‚¬ìœ¼ë©´ ì „ì²´ ì—…ë°ì´íŠ¸ (ì´ë¯¸ì§€ í¬í•¨)
                        existing.category = category
                        existing.region_name = business_data.get('region_name', '')
                        existing.name = business_data.get('name', '')
                        existing.address = business_data.get('address', '')
                        existing.phone_number = business_data.get('phone_number')
                        existing.latitude = Decimal(str(business_data['latitude'])) if business_data.get('latitude') else None
                        existing.longitude = Decimal(str(business_data['longitude'])) if business_data.get('longitude') else None
                        existing.rating = Decimal(str(business_data['rating'])) if business_data.get('rating') else None
                        existing.review_count = business_data.get('review_count', 0)
                        existing.google_maps_url = business_data.get('google_maps_url', '')
                        existing.photo_url = business_data.get('photo_url')  # ë°±ì—…ìš©
                        existing.website_url = business_data.get('website_url')
                        existing.opening_hours = business_data.get('opening_hours')
                        existing.editorial_summary = business_data.get('editorial_summary')
                        existing.business_status = business_data.get('business_status', 'OPERATIONAL')
                        existing.last_review_time = business_data.get('last_review_time')
                        existing.popularity_score = business_data.get('popularity_score', 0)
                        existing.rank_in_region = business_data.get('rank_in_region', 999)
                        existing.last_synced_at = timezone.now()

                        # Google ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ë° custom_photo ì €ì¥ (íŒŒì¼ ì—†ìœ¼ë©´ ë¬´ì¡°ê±´ ì €ì¥)
                        photo_url = business_data.get('photo_url')
                        has_actual_file = existing.custom_photo and existing.custom_photo.name

                        if photo_url and not has_actual_file:
                            # íŒŒì¼ì´ ì—†ìœ¼ë©´ ë¬´ì¡°ê±´ ë‹¤ìš´ë¡œë“œí•´ì„œ ì €ì¥
                            photo_result = self.download_and_save_photo(
                                photo_url,
                                business_data.get('name', ''),
                                google_place_id
                            )
                            if photo_result:
                                content_file, filename = photo_result
                                existing.custom_photo.save(filename, content_file, save=False)
                                logger.info(f"[S3 SAVE] {business_data.get('name')}: ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ")
                            else:
                                logger.warning(f"[S3 FAIL] {business_data.get('name')}: ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")
                        elif has_actual_file:
                            logger.info(f"[SKIP] {business_data.get('name')}: ì´ë¯¸ ì´ë¯¸ì§€ íŒŒì¼ ì¡´ì¬")

                        existing.save()
                        updated_count += 1

                    except LocalBusiness.DoesNotExist:
                        # ì‹ ê·œ ì—…ì²´ ìƒì„±
                        editorial_summary = business_data.get('editorial_summary')
                        logger.info(f"[SAVE] {business_data.get('name')}: editorial_summary={editorial_summary}")

                        # ì—…ì²´ ìƒì„±
                        business = LocalBusiness.objects.create(
                            google_place_id=google_place_id,
                            category=category,
                            region_name=business_data.get('region_name', ''),
                            name=business_data.get('name', ''),
                            address=business_data.get('address', ''),
                            phone_number=business_data.get('phone_number'),
                            latitude=Decimal(str(business_data['latitude'])) if business_data.get('latitude') else None,
                            longitude=Decimal(str(business_data['longitude'])) if business_data.get('longitude') else None,
                            rating=Decimal(str(business_data['rating'])) if business_data.get('rating') else None,
                            review_count=business_data.get('review_count', 0),
                            google_maps_url=business_data.get('google_maps_url', ''),
                            photo_url=business_data.get('photo_url'),  # ì›ë³¸ URLì€ ë°±ì—…ìš©
                            website_url=business_data.get('website_url'),
                            opening_hours=business_data.get('opening_hours'),
                            editorial_summary=editorial_summary,
                            business_status=business_data.get('business_status', 'OPERATIONAL'),
                            last_review_time=business_data.get('last_review_time'),
                            popularity_score=business_data.get('popularity_score', 0),
                            rank_in_region=business_data.get('rank_in_region', 999),
                            last_synced_at=timezone.now(),
                        )

                        # Google ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ë° custom_photoì— ì €ì¥ (ì‹ ê·œ ì—…ì²´ëŠ” ë¬´ì¡°ê±´ ì €ì¥)
                        photo_url = business_data.get('photo_url')
                        if photo_url:
                            photo_result = self.download_and_save_photo(
                                photo_url,
                                business_data.get('name', ''),
                                google_place_id
                            )
                            if photo_result:
                                content_file, filename = photo_result
                                business.custom_photo.save(filename, content_file, save=True)
                                logger.info(f"[S3 SAVE] {business_data.get('name')}: ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ (ì‹ ê·œ)")
                            else:
                                logger.warning(f"[S3 FAIL] {business_data.get('name')}: ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ (ì‹ ê·œ)")

                        created_count += 1

            except LocalBusinessCategory.DoesNotExist:
                errors.append(f"{business_data.get('name')}: ì¹´í…Œê³ ë¦¬ {category_id} ì—†ìŒ")
            except Exception as e:
                errors.append(f"{business_data.get('name')}: {str(e)}")

        return Response({
            'success': True,
            'created': created_count,
            'updated': updated_count,
            'skipped': skipped_count,
            'errors': errors,
            'total': len(businesses_data),
            'message': f'30ì¼ ì´ë‚´ ì—…ë°ì´íŠ¸ëœ {skipped_count}ê°œ ì—…ì²´ëŠ” ìŠ¤í‚µí–ˆìŠµë‹ˆë‹¤ (photo_url ìœ ì§€)'
        })

    @action(detail=False, methods=['post'])
    def google_search_proxy(self, request):
        """Google Places API í”„ë¡ì‹œ (CORS ìš°íšŒ)

        ì‚¬ìš©ë²•: POST /api/local-businesses/google-search-proxy/
        Body: { "textQuery": "...", "locationBias": {...}, "maxResultCount": 20 }
        """
        from django.conf import settings

        logger.info('=' * 80)
        logger.info(f'[google_search_proxy] CALLED - Version: {self._deployment_version}')
        logger.info(f'[google_search_proxy] Request method: {request.method}')
        logger.info(f'[google_search_proxy] Request data: {request.data}')
        logger.info(f'[google_search_proxy] User: {request.user}')
        logger.info('=' * 80)

        api_key = settings.GOOGLE_PLACES_API_KEY
        if not api_key:
            logger.error('[google_search_proxy] API key not configured!')
            return Response(
                {'error': 'Google Places API key not configured'},
                status=status.HTTP_500_INTERNAL_SERVER_ERROR
            )

        try:
            # textQuery ë˜ëŠ” includedTypesë¡œ API ì„ íƒ
            has_text_query = 'textQuery' in request.data
            has_included_types = 'includedTypes' in request.data and request.data['includedTypes']

            if has_text_query:
                # Text Search API
                url = 'https://places.googleapis.com/v1/places:searchText'
                logger.info('[google_search_proxy] Using Text Search API')
            elif has_included_types:
                # Nearby Search API
                url = 'https://places.googleapis.com/v1/places:searchNearby'
                logger.info('[google_search_proxy] Using Nearby Search API')
            else:
                # ê¸°ë³¸ê°’: Nearby Search
                url = 'https://places.googleapis.com/v1/places:searchNearby'
                logger.info('[google_search_proxy] Using Nearby Search API (default)')

            headers = {
                'Content-Type': 'application/json',
                'X-Goog-Api-Key': api_key,
                'X-Goog-FieldMask': 'places.id,places.displayName,places.formattedAddress,places.location,places.rating,places.userRatingCount,places.googleMapsUri,places.businessStatus,places.internationalPhoneNumber,places.websiteUri,places.editorialSummary,places.reviews,places.photos,places.regularOpeningHours',
                'X-Goog-LanguageCode': 'ko'
            }

            logger.info(f'[google_search_proxy] Calling Google API: {url}')
            logger.info(f'[google_search_proxy] Request payload size: {len(str(request.data))} bytes')

            response = requests.post(url, json=request.data, headers=headers, timeout=10)

            logger.info(f'[google_search_proxy] Google API response status: {response.status_code}')
            logger.info(f'[google_search_proxy] Returning response to client')

            # ì‘ë‹µ ê·¸ëŒ€ë¡œ ë°˜í™˜
            return Response(response.json(), status=response.status_code)

        except requests.RequestException as e:
            logger.error('=' * 80)
            logger.error(f'[google_search_proxy] REQUEST EXCEPTION!')
            logger.error(f'[google_search_proxy] Error type: {type(e).__name__}')
            logger.error(f'[google_search_proxy] Error message: {str(e)}')
            logger.error('=' * 80)
            return Response(
                {'error': f'API request failed: {str(e)}'},
                status=status.HTTP_500_INTERNAL_SERVER_ERROR
            )

    @action(detail=True, methods=['get'])
    def photo(self, request, pk=None):
        """ì—…ì²´ ì‚¬ì§„ í”„ë¡ì‹œ (photo_url ë°±ì—…ìš©)

        ì°¸ê³ : custom_photoê°€ ìš°ì„ ìˆœìœ„ì´ë¯€ë¡œ ì´ ì—”ë“œí¬ì¸íŠ¸ëŠ” ê±°ì˜ ì‚¬ìš© ì•ˆ ë¨
        ì‚¬ìš©ë²•: /api/local-businesses/{id}/photo/
        """
        from django.conf import settings

        business = self.get_object()

        if not business.photo_url:
            return HttpResponse(status=404)

        try:
            # photo_urlì— API í‚¤ ì¶”ê°€ (ë°±ì—”ë“œì—ì„œë§Œ ì²˜ë¦¬)
            photo_url_with_key = f"{business.photo_url}&key={settings.GOOGLE_PLACES_API_KEY}"

            # Googleì—ì„œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ (íƒ€ì„ì•„ì›ƒ 5ì´ˆ)
            response = requests.get(photo_url_with_key, timeout=5)

            if response.status_code == 200:
                # Content-Type í™•ì¸ (ê¸°ë³¸ê°’: image/jpeg)
                content_type = response.headers.get('Content-Type', 'image/jpeg')

                # ì´ë¯¸ì§€ë¥¼ í´ë¼ì´ì–¸íŠ¸ì—ê²Œ ì „ë‹¬
                return HttpResponse(
                    response.content,
                    content_type=content_type,
                    headers={
                        'Cache-Control': 'public, max-age=86400',  # 1ì¼ ë¸Œë¼ìš°ì € ìºì‹±
                    }
                )
            else:
                logger.error(f'Failed to fetch photo for business {pk}: {response.status_code}')
                return HttpResponse(status=404)

        except requests.RequestException as e:
            logger.error(f'Error fetching photo for business {pk}: {str(e)}')
            return HttpResponse(status=500)


# ë…ë¦½ì ì¸ view í•¨ìˆ˜ë¡œ google_search_proxy êµ¬í˜„
@csrf_exempt
@api_view(['POST'])
@perm_decorator([AllowAny])
def google_search_proxy_standalone(request):
    """Google Places API í”„ë¡ì‹œ (CORS ìš°íšŒ) - ë…ë¦½ í•¨ìˆ˜ ë²„ì „

    ViewSetì˜ @actionì´ ì‘ë™í•˜ì§€ ì•Šì•„ ë…ë¦½ í•¨ìˆ˜ë¡œ êµ¬í˜„

    ì‚¬ìš©ë²•: POST /api/local-businesses/google-search-proxy/
    Body: { "textQuery": "...", "locationBias": {...}, "maxResultCount": 20 }
    """
    from django.conf import settings

    logger.info('=' * 80)
    logger.info('[google_search_proxy_standalone] CALLED - Standalone version')
    logger.info(f'[google_search_proxy_standalone] Request method: {request.method}')
    logger.info(f'[google_search_proxy_standalone] Request data: {request.data}')
    logger.info('=' * 80)

    api_key = settings.GOOGLE_PLACES_API_KEY
    if not api_key:
        logger.error('[google_search_proxy_standalone] API key not configured!')
        return Response(
            {'error': 'Google Places API key not configured'},
            status=status.HTTP_500_INTERNAL_SERVER_ERROR
        )

    try:
        # textQuery ë˜ëŠ” includedTypesë¡œ API ì„ íƒ
        has_text_query = 'textQuery' in request.data
        has_included_types = 'includedTypes' in request.data and request.data['includedTypes']

        if has_text_query:
            url = 'https://places.googleapis.com/v1/places:searchText'
            logger.info('[google_search_proxy_standalone] Using Text Search API')
        elif has_included_types:
            url = 'https://places.googleapis.com/v1/places:searchNearby'
            logger.info('[google_search_proxy_standalone] Using Nearby Search API')
        else:
            url = 'https://places.googleapis.com/v1/places:searchNearby'
            logger.info('[google_search_proxy_standalone] Using Nearby Search API (default)')

        headers = {
            'Content-Type': 'application/json',
            'X-Goog-Api-Key': api_key,
            'X-Goog-FieldMask': 'places.id,places.displayName,places.formattedAddress,places.location,places.rating,places.userRatingCount,places.googleMapsUri,places.businessStatus,places.internationalPhoneNumber,places.websiteUri,places.editorialSummary,places.reviews,places.photos,places.regularOpeningHours',
            'X-Goog-LanguageCode': 'ko'
        }

        logger.info(f'[google_search_proxy_standalone] Calling Google API: {url}')
        response = requests.post(url, json=request.data, headers=headers, timeout=10)
        logger.info(f'[google_search_proxy_standalone] Google API response: {response.status_code}')

        return Response(response.json(), status=response.status_code)

    except requests.RequestException as e:
        logger.error('=' * 80)
        logger.error(f'[google_search_proxy_standalone] ERROR: {type(e).__name__}')
        logger.error(f'[google_search_proxy_standalone] Message: {str(e)}')
        logger.error('=' * 80)
        return Response(
            {'error': f'API request failed: {str(e)}'},
            status=status.HTTP_500_INTERNAL_SERVER_ERROR
        )



